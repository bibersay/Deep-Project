{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13813,
     "status": "ok",
     "timestamp": 1659432969830,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "X2NMfBavEO7x",
    "outputId": "f4ad9cc6-03a2-4785-fcf5-8da21ea9c728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "Collecting decorator<5.0,>=4.0.2\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\anaconda3\\lib\\site-packages (from moviepy) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\anaconda3\\lib\\site-packages (from moviepy) (2.26.0)\n",
      "Collecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\anaconda3\\lib\\site-packages (from moviepy) (1.21.5)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\anaconda3\\lib\\site-packages (from moviepy) (2.9.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.7-py3-none-win_amd64.whl (22.6 MB)\n",
      "Requirement already satisfied: pillow in c:\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.4)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py): started\n",
      "  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110744 sha256=f6f2390dde890274a7ec6a9df508a3c467059c50b52f9f74fbae0903d5079569\n",
      "  Stored in directory: c:\\users\\khyun\\appdata\\local\\pip\\cache\\wheels\\29\\15\\e4\\4f790bec6acd51a00b67e8ee1394f0bc6e0135c315f8ff399a\n",
      "Successfully built moviepy\n",
      "Installing collected packages: proglog, imageio-ffmpeg, decorator, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.0\n",
      "    Uninstalling decorator-5.1.0:\n",
      "      Successfully uninstalled decorator-5.1.0\n",
      "Successfully installed decorator-4.4.2 imageio-ffmpeg-0.4.7 moviepy-1.0.3 proglog-0.1.10\n",
      "Collecting imageio==2.4.1\n",
      "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from imageio==2.4.1) (1.21.5)\n",
      "Requirement already satisfied: pillow in c:\\anaconda3\\lib\\site-packages (from imageio==2.4.1) (8.4.0)\n",
      "Building wheels for collected packages: imageio\n",
      "  Building wheel for imageio (setup.py): started\n",
      "  Building wheel for imageio (setup.py): finished with status 'done'\n",
      "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303886 sha256=8105bf4db9085c1b0cb936df93cd4942bba1c1205c9470ef25f889de5fbde5e5\n",
      "  Stored in directory: c:\\users\\khyun\\appdata\\local\\pip\\cache\\wheels\\b7\\44\\b7\\2e7cc9c5fe4a893b9cc83a010d4410557bedf6cf3b5829f497\n",
      "Successfully built imageio\n",
      "Installing collected packages: imageio\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.9.0\n",
      "    Uninstalling imageio-2.9.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'c:\\\\anaconda3\\\\scripts\\\\imageio_download_bin.exe'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facenet_pytorch\n",
      "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from facenet_pytorch) (1.21.5)\n",
      "Requirement already satisfied: pillow in c:\\anaconda3\\lib\\site-packages (from facenet_pytorch) (8.4.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from facenet_pytorch) (2.26.0)\n",
      "Requirement already satisfied: torchvision in c:\\anaconda3\\lib\\site-packages (from facenet_pytorch) (0.13.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda3\\lib\\site-packages (from requests->facenet_pytorch) (2.0.4)\n",
      "Requirement already satisfied: typing_extensions in c:\\anaconda3\\lib\\site-packages (from torchvision->facenet_pytorch) (3.10.0.2)\n",
      "Requirement already satisfied: torch==1.12.0 in c:\\anaconda3\\lib\\site-packages (from torchvision->facenet_pytorch) (1.12.0)\n",
      "Installing collected packages: facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy\n",
    "!pip install imageio==2.4.1\n",
    "!pip install facenet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Downloading dlib-19.24.0.tar.gz (3.2 MB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n",
      "Installing collected packages: dlib\n",
      "    Running setup.py install for dlib: started\n",
      "    Running setup.py install for dlib: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\khyun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-c3jzw58k\\\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\khyun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-c3jzw58k\\\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\khyun\\AppData\\Local\\Temp\\pip-wheel-0beff0uk'\n",
      "       cwd: C:\\Users\\khyun\\AppData\\Local\\Temp\\pip-install-c3jzw58k\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\n",
      "  Complete output (8 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  package init file 'tools\\python\\dlib\\__init__.py' not found (or not a regular file)\n",
      "  running build_ext\n",
      "  \n",
      "  ERROR: CMake must be installed to build dlib\n",
      "  \n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for dlib\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\khyun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-c3jzw58k\\\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\khyun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-c3jzw58k\\\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\khyun\\AppData\\Local\\Temp\\pip-record-q_htmx88\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Anaconda3\\Include\\dlib'\n",
      "         cwd: C:\\Users\\khyun\\AppData\\Local\\Temp\\pip-install-c3jzw58k\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\n",
      "    Complete output (8 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    package init file 'tools\\python\\dlib\\__init__.py' not found (or not a regular file)\n",
      "    running build_ext\n",
      "    \n",
      "    ERROR: CMake must be installed to build dlib\n",
      "    \n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\khyun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-c3jzw58k\\\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\khyun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-c3jzw58k\\\\dlib_2d97340d68ee4c46a337bcf156a90e07\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\khyun\\AppData\\Local\\Temp\\pip-record-q_htmx88\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Anaconda3\\Include\\dlib' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mageio (c:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6689,
     "status": "ok",
     "timestamp": 1659432976513,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "6y3uZNw19ep-",
    "outputId": "0399dd66-949c-4c6c-e378-6997d7958cae"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14972/600013845.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVideoStream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import cv2\n",
    "# from moviepy.editor import *\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59659,
     "status": "ok",
     "timestamp": 1659433036167,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "LPYtWMgHTNKV",
    "outputId": "012c9ae2-47fa-4c75-ac33-e4b4e1bc007d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Deep-Project\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Deep-Project/\n",
    "!cp -r cross_cut /content/\n",
    "# !cp cross_cut/blackpink_7.mp4 /content/cross_cut/\n",
    "\n",
    "# %cd /content/cross_cut\n",
    "# !mv shape_predictor_68_face_landmarks.dat /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1659433036167,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "CEbJOPUWOWIC"
   },
   "outputs": [],
   "source": [
    "class Crosscut:\n",
    "    def __init__(self, dist_obj, video_path, output_path):\n",
    "        self.videos_path = video_path                       # 사용할 비디오 저장경로\n",
    "        self.output_path = output_path                      # 결과물 저장경로\n",
    "        self.min_time = 1000.0                              # 비디오중 가장 짧은 길이 저장 변수, 초기화값\n",
    "        video_num = len(os.listdir(self.videos_path))       # 비디오 갯수\n",
    "        self.start_times = [0] * video_num                  # 비디오별 시작시간\n",
    "        self.window_time = 5                               # 비디오별 비교 시간 범위 (start +  window)  \n",
    "        self.padded_time = 10                               # 영상 전환전 최소 유지시간\n",
    "        self.dist_obj = dist_obj                            # 영산간 거리값\n",
    "        self.audioclip = None                               # 음성 데이터\n",
    "        self.extracted_clips_array = []                     # 시작점이 정렬된 비디오\n",
    "        self.con_clips = []                                 # 결과물 저장\n",
    "    \n",
    "    def video_alignment(self):      # 영상들을 extracted_clips_array에 저장\n",
    "        for i in range(len(os.listdir(self.videos_path))):\n",
    "            video_path = os.path.join(self.videos_path, sorted(os.listdir(self.videos_path))[i])\n",
    "            if '.ipynb_checkpoints' in video_path :\n",
    "                continue\n",
    "            clip = VideoFileClip(video_path)\n",
    "            clip = clip.subclip(self.start_times[i], clip.duration)\n",
    "\n",
    "            if self.min_time > clip.duration:               # 가장 짧은 비디오길이로 self.audio와 self.min_time 업데이트\n",
    "                self.audioclip = clip.audio\n",
    "                self.min_time = clip.duration\n",
    "            self.extracted_clips_array.append(clip)\n",
    "        print(f'LOGGER -- {len(self.extracted_clips_array)} will be mixed')\n",
    "    \n",
    "    def select_next_clip(self, t, current_idx):\n",
    "        cur_t = t\n",
    "        next_t = min(t + self.window_time, self.min_time)\n",
    "        reference_clip = self.extracted_clips_array[current_idx].subclip(cur_t, next_t)     # 기준 영상 설정\n",
    "        d = float('Inf')\n",
    "        cur_clip = None\n",
    "        min_idx = (current_idx + 1) % len(self.extracted_clips_array)                       # 다음 영상 초기화\n",
    "\n",
    "        for video_idx in range(len(self.extracted_clips_array)):                            # 전체 영상 비교\n",
    "            if video_idx == current_idx:\n",
    "                continue\n",
    "            clip = self.extracted_clips_array[video_idx].subclip(cur_t, next_t)\n",
    "            cur_d, plus_frame = self.dist_obj.distance(reference_clip, clip)                 # reference와 clip 간 거리 비교\n",
    "            print(f'current video_idx : {current_idx} , compare video_idx : {video_idx}, distance : {cur_d}, compared end_time : {cur_t + plus_frame}')\n",
    "            if d > cur_d:\n",
    "                d = cur_d\n",
    "                min_idx = video_idx\n",
    "                next_t = cur_t + plus_frame\n",
    "                cur_clip = reference_clip.subclip(0, plus_frame)                     # plus_frame 까지는 refernce, 이후로는 min_idx 영상 사용\n",
    "        \n",
    "        if cur_clip : \n",
    "            clip = cur_clip\n",
    "        else :\n",
    "            clip = reference_clip\n",
    "        print(f'insert video idx : {min_idx}, insert time : {t} to {next_t}')\n",
    "        self.con_clips.append(clip)\n",
    "\n",
    "        t = next_t\n",
    "        return t, min_idx\n",
    "\n",
    "    def add_padding(self, t, next_idx):                 # con_clips에 next_idx 영상의 t시간 추가\n",
    "        print(f'insert idx : {next_idx}')\n",
    "        pad_clip = self.extracted_clips_array[next_idx].subclip(t, min(self.min_time, t + self.padded_time))\n",
    "        self.con_clips.append(pad_clip)\n",
    "\n",
    "        t = min(self.min_time, t + self.padded_time)\n",
    "        return t, next_idx\n",
    "\n",
    "    def write_video(self):\n",
    "        final_clip = concatenate_videoclips(self.con_clips)\n",
    "        if self.audioclip != None:\n",
    "            print('Not None')\n",
    "            final_clip.audio = self.audioclip\n",
    "        final_clip.write_videofile(self.output_path, threads=5)        \n",
    "        return final_clip\n",
    "    \n",
    "    def generate_video(self):                   # video 생성 main 함수\n",
    "        self.video_alignment()\n",
    "        t = 10\n",
    "        current_idx = 0\n",
    "        self.con_clips.append(self.extracted_clips_array[current_idx].subclip(0, min(t, int(self.min_time))))\n",
    "\n",
    "        while t < int(self.min_time/10):           # min_time(audio 길이) 까지 반복\n",
    "            t, min_idx = self.select_next_clip(t, current_idx)\n",
    "            t, current_idx = self.add_padding(t, min_idx)\n",
    "        \n",
    "        final_clip = self.write_video()\n",
    "        return final_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1659433036168,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "XWe3KMmugqOo"
   },
   "outputs": [],
   "source": [
    "class RandomDistance():\n",
    "    def distance(self, reference_clip, compare_clip):\n",
    "        dur_end = min(reference_clip.duration, compare_clip.duration)\n",
    "        return random.randrange(1,100), min(dur_end, random.randrange(50,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1659433036621,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "gTuNOwWv9Tmm"
   },
   "outputs": [],
   "source": [
    "class FaceDistance:         # facedistance 계산\n",
    "    def __init__(self, shape_predictor_path, face_embedding_penalty = None):\n",
    "        self.skip_frame_rate = 4                                    # 4frame 마다 distance 계산\n",
    "        self.minimax_frames = 5                                     # 연속되 5frame을 계산\n",
    "        self.shape_predictor = shape_predictor_path\n",
    "        self.face_embedding_penalty =face_embedding_penalty\n",
    "\n",
    "    def extracted_landmark(self, reference_clip, compare_clip):\n",
    "        self.clips = [reference_clip, compare_clip]                 # 영상 저장\n",
    "        detector = dlib.get_frontal_face_detector()                 # face position detector\n",
    "        predictor = dlib.shape_predictor(self.shape_predictor)      # landmark detector\n",
    "        clips_frame_info = []\n",
    "        \n",
    "        for clip in self.clips:\n",
    "            i = 0\n",
    "            every_frame_info = []\n",
    "            while True:\n",
    "                frame = clip.get_frame(i * 1.0 / clip.fps)          # clip에서 frame 을 image로 추출\n",
    "                i += self.skip_frame_rate                           # 다음 i-th frame \n",
    "                if (i * 1.0 / clip.fps) > clip.duration:\n",
    "                    break\n",
    "                \n",
    "                frame = imutils.resize(frame, width = 800)          # 이미지 축소로 연산속도 향상\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)      # gray 채널만 사용해서 연산속도 향상\n",
    "                rects = detector(gray, 0)                           # face position box 추출\n",
    "\n",
    "                if len(rects)> 0:\n",
    "                    max_width = 0\n",
    "                    max_rect = None\n",
    "                    for rect in rects:\n",
    "                        if int(rects[0].width()) > max_width:       # 가장 큰 얼굴만 사용\n",
    "                            max_rect = rect\n",
    "                    shape = predictor(gray, max_rect)\n",
    "                    shape = imutils.face_utils.shape_to_np(shape)\n",
    "                    every_frame_info.append(shape)\n",
    "                \n",
    "                else :                                              # face가 없으면 빈 list 전달\n",
    "                    every_frame_info.append([])\n",
    "            \n",
    "            clips_frame_info.append(np.array(every_frame_info))\n",
    "        cv2.destroyAllWindows()\n",
    "        return clips_frame_info\n",
    "    \n",
    "    def embedding_cosine_distance(self, reference_frame, compare_frame):\n",
    "        face_detector = MTCNN(select_largest = True)                        # face detector\n",
    "        embed_model = InceptionResnetV1(pretrained = 'vggface2').eval()     # face embedding model\n",
    "\n",
    "        reference_frame = np.array(reference_frame)\n",
    "        compare_frame = np.array(compare_frame)\n",
    "        try :                                                               # face_detector return값이 없을경우 오류가 나기에 try사용\n",
    "            reference_frame_detected = face_detector(reference_frame)\n",
    "            compare_frame_detected = face_detector(compare_frame)\n",
    "        \n",
    "        except :\n",
    "            cosine_dist=1\n",
    "            return cosine_dist\n",
    "\n",
    "        reference_frame_embed = embed_model(reference_frame_detected.unsqueeze(0)).detach().numpy()   \n",
    "        compare_frame_embed = embed_model(compare_frame_detected.unsqueeze(0)).detach().numpy()\n",
    "        reference_frame_embed = np.squeeze(reference_frame_embed)\n",
    "        compare_frame_embed = np.squeeze(compare_frame_embed)\n",
    "\n",
    "        cosine_dist = 1 - np.dot(reference_frame_embed, compare_frame_embed) /  \\\n",
    "                     (np.linalg.norm(reference_frame_embed) * np.linalg.norm(compare_frame_embed))\n",
    "        \n",
    "        return cosine_dist\n",
    "\n",
    "    def get_all_frame_distance(self, clips_frame_info, min_size):\n",
    "        dist_arr = []\n",
    "        for i in range(min_size -1):\n",
    "            if len(clips_frame_info[0][i]) > 0 and len(clips_frame_info[1][i+1]) > 0 :\n",
    "                l = 36      # left eye landmark\n",
    "                r = 45      # right eye landmark\n",
    "                #clips_frame_info[0][i][l][0] : 0: 첫번째 영상 // i : i번째 landmark 정보 // l : lefteye // 0 : x좌표\n",
    "                left_eye = ((clips_frame_info[0][i][l][0] - clips_frame_info[1][i+1][l][0]) **2 + \\\n",
    "                            (clips_frame_info[0][i][l][1] - clips_frame_info[1][i+1][l][1]) **2) **0.5      # frame간 left eye 거리 \n",
    "                right_eye = ((clips_frame_info[0][i][r][0] - clips_frame_info[1][i+1][r][0]) **2 + \\\n",
    "                            (clips_frame_info[0][i][r][1] - clips_frame_info[1][i+1][r][1]) **2) **0.5      # frame간 right eye 거리\n",
    "                total_diff = left_eye + right_eye\n",
    "                dist_arr.append(total_diff)\n",
    "            else : \n",
    "                dist_arr.append(None)\n",
    "        return dist_arr\n",
    "    \n",
    "    def distance(self, reference_clip, compare_clip):\n",
    "        clips_frame_info = self.extracted_landmark(reference_clip, compare_clip)      # landmark 추출\n",
    "        min_size = min(len(clips_frame_info[0]), len(clips_frame_info[1]))          # 1, 2번째 영상중 짧은영상을 기준 \n",
    "        dist_arr = self.get_all_frame_distance(clips_frame_info, min_size)          # landmark distance 계산\n",
    "        clips = [reference_clip, compare_clip]\n",
    "        minimax_frames = self.minimax_frames\n",
    "        min_diff = np.float('Inf')\n",
    "        min_idx = 0\n",
    "\n",
    "        for i in range(min_size - (minimax_frames -1)):\n",
    "            start_minmax_idx = 0 if (i - minimax_frames) < 0 else i - minimax_frames\n",
    "            if (None not in dist_arr[start_minmax_idx : i + minimax_frames]):       # 얼굴이 없는경우 None\n",
    "                tmp_max = np.max(dist_arr[start_minmax_idx : i + minimax_frames])   # dist_arr의 max를 대표값으로 설정\n",
    "                if min_diff > tmp_max:\n",
    "                    min_diff = tmp_max\n",
    "                    min_idx = i\n",
    "        \n",
    "        if self.face_embedding_penalty != None and min_diff < np.float(\"Inf\"):\n",
    "            ref_frame = reference_clip.get_frame(min_idx * 1.0 / reference_clip.fps)\n",
    "            frame = compare_clip.get_frame(min_idx * 1.0 / compare_clip.fps)\n",
    "            cosine_dist = self.embedding_cosine_distance(ref_frame, frame)\n",
    "            min_diff += cosine_dist * self.face_embedding_penalty\n",
    "        \n",
    "        return min_diff, (min_idx * self.skip_frame_rate) / self.clips[0].fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1659433036623,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "Ox8tvGBqj97e"
   },
   "outputs": [],
   "source": [
    "class PoseDistance:\n",
    "    def __init__(self):\n",
    "        self.SKIP_FRAME_RATE = 10\n",
    "        self.MINIMAX_FRAME = 4\n",
    "        self.model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "        self.model.eval()\n",
    "        os.environ[\"KMP_DUPLICATE_LIB_OK\"] = 'True'\n",
    "    \n",
    "    def extract_boxes(self, reference_clip, compare_clip):\n",
    "        self.clips = [reference_clip, compare_clip]\n",
    "        clips_frame_info = []\n",
    "        for clip in self.clips:\n",
    "            i = 0\n",
    "            every_frame_info = []\n",
    "            while True :\n",
    "                i += self.SKIP_FRAME_RATE\n",
    "                if (i * 1.0 / clip.fps) > clip.duration:\n",
    "                    break\n",
    "\n",
    "                # model에 넣을 input transform    \n",
    "                frame = clip.get_frame(i * 1.0 / clip.fps)\n",
    "                frame = imutils.resize(frame, width = 480)  # 이미지 축소로 연산속도 향상\n",
    "                frame = frame / 255                         # model의 input range(0,1)\n",
    "                frame = np.transpose(frame, (2,0,1))        # get_frame의 output (H, W, C) -> model의 input (C, H, W)으로 변경\n",
    "\n",
    "                if torch.cuda.is_available():               #GPU 사용\n",
    "                    x = [torch.from_numpy(frame).float().cuda()]       # model에 넣기전 tensor, cuda로 변환\n",
    "                    self.model.to('cuda')\n",
    "                else :\n",
    "                    x = [torch.from_numpy(frame).float()]       # model에 넣기전 tensor로 변환\n",
    "\n",
    "                predictions = self.model(x)\n",
    "                prediction = predictions[0]\n",
    "                # faster-RCNN output을 변형\n",
    "                each_box_list = zip(prediction['boxes'].tolist(), prediction['labels'].tolist(), prediction['scores'].tolist())\n",
    "                # 사람(1), 0.95% 이상 필터\n",
    "                filtered_box_list = filter(lambda x : x[1] == 1 and x[2] >=  0.95, each_box_list)\n",
    "                # center 값 저장\n",
    "                filtered_center_dot_list = list(map(lambda x : [(x[0][0] + x[0][2]) / 2, (x[0][1] + x[0][3]) /2], filtered_box_list))\n",
    "                sorted_dot_list = sorted(filtered_center_dot_list, key = lambda x : x[0])\n",
    "                every_frame_info.append(sorted_dot_list)\n",
    "            clips_frame_info.append(np.array(every_frame_info))\n",
    "        return clips_frame_info\n",
    "    \n",
    "    def get_all_frame_distance(self, clips_frame_info, min_size):\n",
    "        dist_arr = list()\n",
    "        for i in range(min_size):\n",
    "            if len(clips_frame_info[0][i]) > 0 and len(clips_frame_info[1][i]) > 0:\n",
    "                ref_frame_dots = clips_frame_info[0][i]\n",
    "                compare_frame_dots = clips_frame_info[1][i]\n",
    "                min_dot_num = min(len(ref_frame_dots), len(compare_frame_dots))             # 두 영상 모두 dot이 있어야 하므로 최소 개수 설정\n",
    "                dot_num_diff = abs(len(ref_frame_dots) - len(compare_frame_dots))           # dot 개수 차이 저장\n",
    "                # 영상의 점이 없을경우 penalty 사용 - 영상의 가장 먼거리 * dot 개수 차이\n",
    "                penalty = ((self.clips[0].w **2 + self.clips[0].h **2) **.5) * dot_num_diff\n",
    "                total_diff = penalty * dot_num_diff\n",
    "                # print('total_diff', total_diff, '  penalty', penalty)\n",
    "\n",
    "                for dot_idx in range(min_dot_num):\n",
    "                    total_diff += ((ref_frame_dots[dot_idx][0] - compare_frame_dots[dot_idx][0]) **2 + \\\n",
    "                                   (ref_frame_dots[dot_idx][1] - compare_frame_dots[dot_idx][1]) **2) **.5\n",
    "                    dist_arr.append(total_diff)\n",
    "            else : \n",
    "                dist_arr.append(None)\n",
    "        print(f'dist_arr : {dist_arr}')\n",
    "        return dist_arr\n",
    "    \n",
    "    def distance(self, reference_clip, compare_clip):\n",
    "        clips_frame_info = self.extract_boxes(reference_clip, compare_clip)\n",
    "        min_size = min(len(clips_frame_info[0]), len(clips_frame_info[1]))\n",
    "        dist_arr = self.get_all_frame_distance(clips_frame_info, min_size)\n",
    "        min_diff = np.float(\"Inf\")\n",
    "        min_idx = 0\n",
    "        \n",
    "        for i in range(min_size - (self.MINIMAX_FRAME -1)):\n",
    "            start_minimax_idx = 0 if (i -self.MINIMAX_FRAME) < 0 else i - self.MINIMAX_FRAME\n",
    "            print(f'dist_arr[{start_minimax_idx} : {i + self.MINIMAX_FRAME}] : ', dist_arr[i : i + self.MINIMAX_FRAME])                \n",
    "            if (None not in dist_arr[start_minimax_idx : i + self.MINIMAX_FRAME]) :\n",
    "                tmp_max = np.max(dist_arr[i : i + self.MINIMAX_FRAME])\n",
    "                if min_diff > tmp_max : \n",
    "                    min_diff = tmp_max\n",
    "                    min_idx = i\n",
    "                    print('min_idx : ', min_idx, 'tmp_max : ', tmp_max)\n",
    "        \n",
    "        return min_diff, (min_idx * self.SKIP_FRAME_RATE) / reference_clip.fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1659433036624,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "nPEWheALY43M"
   },
   "outputs": [],
   "source": [
    "# cross_cut.write_video(codec=\"libvpx\")\n",
    "# !cp /content/my_stagemix.mp4 /content/drive/MyDrive/Deep-Project/cross_cut\n",
    "# pose_distance.model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177809,
     "status": "ok",
     "timestamp": 1659433294857,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "Wrxi5FgRBbT2",
    "outputId": "7a6d8cdb-45ef-4bd7-d7dc-003592ab8114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/my_stagemix.mp4\n",
      "LOGGER -- 6 will be mixed\n",
      "current video_idx : 0 , compare video_idx : 1, distance : 15, compared end_time : 15\n",
      "current video_idx : 0 , compare video_idx : 2, distance : 30, compared end_time : 15\n",
      "current video_idx : 0 , compare video_idx : 3, distance : 52, compared end_time : 15\n",
      "current video_idx : 0 , compare video_idx : 4, distance : 1, compared end_time : 15\n",
      "current video_idx : 0 , compare video_idx : 5, distance : 81, compared end_time : 15\n",
      "insert video idx : 4, insert time : 10 to 15\n",
      "insert idx : 4\n",
      "Not None\n",
      "[MoviePy] >>>> Building video /content/my_stagemix.mp4\n",
      "[MoviePy] Writing audio in my_stagemixTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4266/4266 [00:13<00:00, 324.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] Writing video /content/my_stagemix.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 750/750 [02:23<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /content/my_stagemix.mp4 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<moviepy.video.VideoClip.VideoClip at 0x7f6a2a7a0f50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'random'\n",
    "video_path = '/content/cross_cut'\n",
    "output_path = '/content/my_stagemix.mp4'\n",
    "# shape_predictor_path = '/content/shape_predictor_68_face_landmarks.dat'\n",
    "face_embedding_penalty = 100\n",
    "\n",
    "print(output_path)\n",
    "if method == 'random':\n",
    "    random_distance = RandomDistance()\n",
    "    cross_cut = Crosscut(random_distance, video_path, output_path)\n",
    "\n",
    "elif method == 'face':\n",
    "    face_distance = FaceDistance(shape_predictor_path, face_embedding_penalty)\n",
    "    cross_cut = Crosscut(face_distance, video_path, output_path)\n",
    "\n",
    "elif method == 'pose':\n",
    "    pose_distance = PoseDistance()\n",
    "    cross_cut = Crosscut(pose_distance, video_path, output_path)\n",
    "\n",
    "cross_cut.generate_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1659433477087,
     "user": {
      "displayName": "bong bong",
      "userId": "17774416216702601338"
     },
     "user_tz": -540
    },
    "id": "rLBsaheWCvE-"
   },
   "outputs": [],
   "source": [
    "!cp /content/my_stagemix.mp4 /content/drive/MyDrive/Deep-Project/cross_cut/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMxV2Suyb4F9Un742r0vTdh",
   "collapsed_sections": [],
   "mount_file_id": "13uCBJEpgS1y64QLmDKS72SEpgbYNxkfS",
   "name": "cross_cut.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
